{
  "name": "redis-convoy",
  "version": "0.1.2",
  "description": "Redis-backed job queueing",
  "main": "lib/convoy.js",
  "scripts": {
    "test": "make test"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/gosquared/convoy"
  },
  "keywords": [
    "job",
    "message",
    "redis",
    "queue"
  ],
  "author": {
    "name": "Geoff Wagstaff"
  },
  "license": "MIT",
  "dependencies": {
    "config": "~0.4.17",
    "debug": "~0.7.0",
    "redis": "https://github.com/gosquared/node_redis/tarball/master",
    "hiredis": "~0.1.14"
  },
  "devDependencies": {
    "mocha": "~1.6.0",
    "should": "~1.2.0"
  },
  "readme": "## Convoy\n\nConvoy is a Node.JS module for working with a Redis-backed job queue.\n\nIt is designed to be distributed and atomic, orchestrating the queuing, delegation and processing of jobs with unique IDs. \n\nThis means that you can have multiple job publishers and multiple consumers for the same queues, even across many servers, and convoy will ensure that unique jobs only get queued once at a time, and delegated to a single worker until queued again.\n\n### Installation\n    npm install redis-convoy\n\n### Usage\n\n````\nvar Convoy = require('redis-convoy');\n\n// Create a queue object\nvar q = Convoy.createQueue('monsterTrucks');\n\n// Set up our job. Each job must have an ID\nvar jobID = 1;\nvar job = new Convoy.Job(jobID);\n\n// Queue the job once only. If another instance of convoy tries to add a job of the same ID at the same time before any workers process it, it won't get duplicated in the queue\n\nq.addJob(job);\n\n// Set up a worker\nq.process(function(job, done){\n\tconsole.log(job);\n\tdone(); // or done('an error') if error during processing of the job\n});\n\n````\n\n### Running tests\nMake sure you have a local redis running on localhost:6379 (or change these settings in config/default.js), then run:\n\n    make test\n\n\n#### Inspiration\n\nConvoy was inspired by TJ Holowaychuk's [kue](https://github.com/LearnBoost/kue) module. I was using Kue, but was caught up with some problems when workers did not fully ack the job, causing it to get stuck in the active/inactive lists. Additionally, kue did not seem to offer convenient support for ensuring unique jobs only get queued once, which is the main focus of convoy.",
  "readmeFilename": "README.md",
  "_id": "redis-convoy@0.1.2",
  "_from": "redis-convoy@"
}
